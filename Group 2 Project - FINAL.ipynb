{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4fb629f9-c1c8-40b2-88a3-eb5133c9c899",
   "metadata": {},
   "source": [
    "# Group 2 Project: Used Cars"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e55aec9c-86c0-4234-a40e-685e605121c5",
   "metadata": {},
   "source": [
    "## Description to run the notebook:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38aa9fb3-4b4b-4ae7-9efa-078cbd1ab9a2",
   "metadata": {},
   "source": [
    "### After downloading the vehicles.csv file, the file needs to be put into the same folder which holds our project (and have the name \"vehicles.csv\"). Our csv reader assumes that the file is directly accessible from the same folder, and needs to see it, otherwise it'll throw an error. From there, all cells can be ran as normal. (NOTE: Our dataset has approximately 450,000 entries, so the file is 1.4 Gigabytes and will take some time to upload to jupyter lab and read)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "46e445e0-48af-40c4-b299-302d8bab4d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import pandas as pd\n",
    "from typing import List\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.metrics import root_mean_squared_error, r2_score, mean_absolute_error, mean_squared_error\n",
    "#Creating a function to collect the relative absolute error\n",
    "def relative_absolute_error(a, b):\n",
    "    meanabs = mean_absolute_error(a, b)\n",
    "    a_mean = np.mean(a)\n",
    "    return meanabs/(mean_absolute_error(a, np.full(a.shape, a_mean)))\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from typing import Dict\n",
    "import csv\n",
    "from typing import NamedTuple\n",
    "from scipy.spatial import distance\n",
    "from collections import defaultdict\n",
    "from sklearn import metrics\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "\n",
    "Vector = List[float]\n",
    "pd.options.mode.chained_assignment = None "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "523dded5-0914-472f-8f18-a2ff18c64a42",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'vehicles.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# The car dataset in its original form before any testing\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m original \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvehicles.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mengine\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpython\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlatin1\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/3360FALL2024/env/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/3360FALL2024/env/lib/python3.10/site-packages/pandas/io/parsers/readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/3360FALL2024/env/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/3360FALL2024/env/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/3360FALL2024/env/lib/python3.10/site-packages/pandas/io/common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'vehicles.csv'"
     ]
    }
   ],
   "source": [
    "# The car dataset in its original form before any testing\n",
    "original = pd.read_csv(\"vehicles.csv\", engine = \"python\", encoding = \"latin1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b12aea69-22d0-45f8-bfd5-8f54133028a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#########\n",
    "#Extracting the input features from the original dataset\n",
    "usedcars = original[[\"price\", \"year\", \"manufacturer\", \"condition\", \"cylinders\", \"odometer\", \"title_status\", \"transmission\", \"drive\", \"type\", \"model\"]]\n",
    "#########"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18a0e267-8bef-418e-afbd-70df7d2cbfaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Consider only values which don't have a null value\n",
    "newUsedCars = usedcars.dropna()\n",
    "\n",
    "#Find outliers within the dataset to reduce extremeities and skewness\n",
    "def find_outliers_iqr(df, column):\n",
    "    q1 = df[column].quantile(0.25)\n",
    "    q3 = df[column].quantile(0.75)\n",
    "    iqr = q3 - q1\n",
    "    lower_bound = q1 - 1.5 * iqr\n",
    "    upper_bound = q3 + 1.5 * iqr\n",
    "    df.drop(df[(df[column] < lower_bound)].index, inplace = True)\n",
    "    df.drop(df[(df[column] > upper_bound)].index, inplace = True)\n",
    "    \n",
    "find_outliers_iqr(newUsedCars, 'price')\n",
    "find_outliers_iqr(newUsedCars, 'odometer')\n",
    "find_outliers_iqr(newUsedCars, 'year')\n",
    "\n",
    "##Turns string to int value for relevant input features\n",
    "le = LabelEncoder()\n",
    "newUsedCars['conditionint'] = le.fit_transform(newUsedCars['condition'])\n",
    "newUsedCars[\"title_statusint\"] = le.fit_transform(newUsedCars[\"title_status\"])\n",
    "newUsedCars[\"transmissionint\"] = le.fit_transform(newUsedCars[\"transmission\"])\n",
    "newUsedCars[\"manufacturerint\"] = le.fit_transform(newUsedCars[\"manufacturer\"])\n",
    "newUsedCars[\"cylindersint\"] = le.fit_transform(newUsedCars[\"cylinders\"])\n",
    "newUsedCars[\"driveint\"] = le.fit_transform(newUsedCars[\"drive\"])\n",
    "newUsedCars[\"typeint\"] = le.fit_transform(newUsedCars[\"type\"])\n",
    "newUsedCars[\"modelint\"] = le.fit_transform(newUsedCars[\"model\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b4c3cbe-5889-4d3d-b63e-63ac70ce747e",
   "metadata": {},
   "source": [
    "# Data Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd635647-9e67-4bfb-a552-68ab69bbf04d",
   "metadata": {},
   "source": [
    "## Bar Charts for categorical variables and their mean prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec48897-46ce-4188-bfd2-69d4739242bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "newUsedCars.groupby([\"condition\"])[\"price\"].mean().plot(kind=\"bar\", title=\"Prices by Condition\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf50e4a7-3153-4328-8442-fe15b0ec4dd4",
   "metadata": {},
   "source": [
    "#### As seen by this graph, the mean value of a car generally decreases as its condition gets worse, though one exception are cars in \"good\" condition, which has a slightly higher mean price than the other categories. This could be the result of most of the cars in the dataset having the \"good\" condition applied to them compared to the others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e61027c-e562-4d5a-a08a-ea546385a22c",
   "metadata": {},
   "outputs": [],
   "source": [
    "newUsedCars.groupby([\"title_status\"])[\"price\"].mean().plot(kind=\"bar\", title=\"Prices by Car Status\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed3e5bea-4a8d-4e2b-8215-9f4c11c5ac79",
   "metadata": {},
   "source": [
    "#### The results from this graph are as expected, with cars that are more complete and finished being more valuable. Cars with a lien status ont hem are sold off at even higher prices than the rest, though the means are still closer together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e1806fb-8706-4dda-a599-f0ac84d94077",
   "metadata": {},
   "outputs": [],
   "source": [
    "newUsedCars.groupby([\"transmission\"])[\"price\"].mean().plot(kind=\"bar\", title=\"Prices by Transmission Type\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10830d3d-1f0e-4468-b202-dd33ca1c272b",
   "metadata": {},
   "source": [
    "#### There isn't much difference between the mean prices of the types of transmissions, though cars with alternative transmissions are more valuable overall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b8ca84-9728-4e47-be3c-e4605153ebeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "newUsedCars.groupby([\"manufacturer\"])[\"price\"].mean().plot(kind=\"bar\", title=\"Prices by Manufacturer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa53d770-9753-4ab6-96ef-e4c77ba56831",
   "metadata": {},
   "source": [
    "#### There are strong differences among the mean prices of cars by their manufacutrer. Generally more high-class manufactuers like Alfa-Romeo and Aston-Martin are far more valuable than more general car manufacturers like Chevrolet and Ford."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c5f83f-d5d4-4e2f-a4d1-b35401d46218",
   "metadata": {},
   "outputs": [],
   "source": [
    "newUsedCars.groupby([\"cylinders\"])[\"price\"].mean().plot(kind=\"bar\", title=\"Prices by Number of Cylinders\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75815e7d-5e60-4f08-8f6b-8f9d98e8e5f5",
   "metadata": {},
   "source": [
    "#### Though both 10-cylinder and 5-cylinder cars break from this trend, the mean price of a car generally increases as the number of cylinders increases giving a somewhat linear relationship between cylinders and prices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d3edf90-e129-42e6-8a34-c7fce34aeed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "newUsedCars.groupby([\"drive\"])[\"price\"].mean().plot(kind=\"bar\", title=\"Prices by Their Type of Drive\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55a91fd3-ca1c-4fcb-bd66-fa06b2bf672c",
   "metadata": {},
   "source": [
    "#### Cars which have a forward wheel drive have far lower mean prices than cars with a rear wheel or 4 wheel drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c4564d-9eef-45ad-8db8-2c1a2375d3b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "newUsedCars.groupby([\"type\"])[\"price\"].mean().plot(kind=\"bar\", title=\"Prices by the type of car\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daa75ced-1983-4b8b-90ae-b83b6e2c2b93",
   "metadata": {},
   "source": [
    "#### Mean prices differ heavily based on what type a specific car is, ranging from hatchbacks and mini-vans to coupes and pickups, the differences in types should be a good indicator of a specific car's value."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2ba33a7-6a67-41e8-8096-6cecbd3bcdf5",
   "metadata": {},
   "source": [
    "## Exploration of independent sellers vs businesses on Cragislist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0566919-2c3a-4221-8e4e-cca7d4de42ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "vehicles = original.copy() # Creating a copy to preserve the\n",
    "vehicles = vehicles.dropna(subset=['description', 'price', 'odometer', 'manufacturer', 'model']) \n",
    "find_outliers_iqr(vehicles, 'price')\n",
    "find_outliers_iqr(vehicles, 'odometer')\n",
    "find_outliers_iqr(vehicles, 'year')\n",
    "vehicles = vehicles.drop_duplicates(subset=['description'], keep='first')\n",
    "ogDf = vehicles.copy()\n",
    "carvana = vehicles[vehicles['description'].str.contains(\"Carvana\", case=False, na=False)]\n",
    "dealership = vehicles[vehicles['description'].str.contains(\"dealership\", case=False, na=False)]\n",
    "newCar =  vehicles[\n",
    "    vehicles[\"description\"].str.contains(\"new car\", case=False, na=False) &\n",
    "    ~vehicles[\"description\"].str.contains(\"like new\", case=False, na=False)\n",
    "]\n",
    "finance = vehicles[vehicles['description'].str.contains(\"financing available\", case=False, na=False)]\n",
    "\n",
    "combined_indices = newCar.index.union(carvana.index).union(finance.index).union(dealership.index)\n",
    "vehicles = vehicles.drop(combined_indices)\n",
    "vehicles = vehicles.reset_index(drop=True)\n",
    "carvana = carvana.reset_index(drop=True)\n",
    "newCar = newCar.reset_index(drop=True)\n",
    "finance = finance.reset_index(drop=True)\n",
    "dealership = dealership.reset_index(drop=True)\n",
    "usedDealerShips = pd.concat([carvana, dealership, newCar, finance], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b1221cd-d0c5-44b2-ba7b-c183a86bb707",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Dataset size (Bar duplicates and null values): {ogDf.shape[0]}\")\n",
    "print(f\"Vehicles listed by Carvana: {carvana.shape[0]}\")\n",
    "print(f\"Dealership vehicles: {dealership.shape[0]}\")\n",
    "print(f\"New cars (excluding 'like new'): {newCar.shape[0]}\")\n",
    "print(f\"Vehicles with financing available: {finance.shape[0]}\")\n",
    "print(f\"Remaining vehicles after removing combined indices: {vehicles.shape[0]}\")\n",
    "print(f\"Original dataset size: {original.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd5445fd-d7e6-49cf-8da7-2bfb39be86e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "iterable = ['price', 'odometer', 'year']\n",
    "for i in iterable:\n",
    "    plt.hist(vehicles[i], label = \"Independent sellers\", alpha=0.8)\n",
    "    plt.hist(usedDealerShips[i], label = \"Dealerships\", alpha=0.8)\n",
    "    plt.title(f'Distribution of {i}')\n",
    "    plt.xlabel(i)\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0ea7979-882b-4d16-8851-f05d97300b09",
   "metadata": {},
   "source": [
    "## The histograms for year, price, and year indicate skew. For dealerships, the distibution of year of cars is skewed left but independent sellers aren't as skewed. The distribution of odometer is also heavily skewed by dealerships but right this time instead of left. The distribution of odometer isn't heavily skewed in entries by independent sellers. In the distribution of price we see the opposite. The distribution of price in entries by independent sellers are skewed right heavily but dealerships is not skewed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4348f2db-51b3-45de-8b4e-8e5f3fc8ceb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = [vehicles, usedDealerShips, ogDf, original, newUsedCars]\n",
    "dfNames = [ 'Dataset of cars sold by independent sellers (with outliers removed, without duplicates and null values for certain features kept)',\n",
    "           'Dataset of cars sold by dealerships (with outliers removed, without duplicates and null values for certain features kept)',\n",
    "           \"Data set with both sellers (with outliers removed, without duplicates and null values for certain features kept)\",\n",
    "           \"Dataset in it's original state\",\n",
    "           \"Data set with outliers removed and all null values for all features removed\"]\n",
    "for i in dfs:\n",
    "    i['conditionint'] = le.fit_transform(i['condition'])\n",
    "    i[\"title_statusint\"] = le.fit_transform(i[\"title_status\"])\n",
    "    i[\"transmissionint\"] = le.fit_transform(i[\"transmission\"])\n",
    "    i[\"manufacturerint\"] = le.fit_transform(i[\"manufacturer\"])\n",
    "    i[\"modelint\"] = le.fit_transform(i[\"model\"])\n",
    "    i[\"cylindersint\"] = le.fit_transform(i[\"cylinders\"])\n",
    "    i[\"driveint\"] = le.fit_transform(i[\"drive\"])\n",
    "    i[\"typeint\"] = le.fit_transform(i[\"type\"])\n",
    "for df, name in zip(dfs, dfNames):\n",
    "    print(f\"\\nAnalysis for: {name}\\n\")\n",
    "\n",
    "    # Correlation matrix\n",
    "    print(\"Correlation with 'price':\")\n",
    "    correlation_matrix = df[['price', 'odometer', 'conditionint', 'title_statusint', 'transmissionint', \n",
    "                              'manufacturerint', 'cylindersint', 'driveint', 'typeint', 'modelint']].corr()\n",
    "    print(correlation_matrix['price'].sort_values(ascending=False))\n",
    "    \n",
    "    # Standard deviation\n",
    "    dev = df[['price', 'odometer', 'year', 'conditionint', 'title_statusint', 'transmissionint', \n",
    "                  'manufacturerint', 'cylindersint', 'driveint', 'typeint', 'modelint']].std()\n",
    "    print(\"\\nStandard Deviation:\")\n",
    "    print(dev)\n",
    "    \n",
    "    # Covariance matrix\n",
    "    covariance_matrix = df[['price', 'odometer', 'year', 'conditionint', 'title_statusint', 'transmissionint', \n",
    "                             'manufacturerint', 'cylindersint', 'driveint', 'typeint', 'modelint']].cov()\n",
    "    print(\"\\nCovariance with 'price':\")\n",
    "    print(covariance_matrix['price'])\n",
    "    # Variance\n",
    "    variance = df[['price', 'odometer', 'year', 'conditionint', 'title_statusint', 'transmissionint', \n",
    "                   'manufacturerint', 'cylindersint', 'driveint', 'typeint', 'modelint']].var()\n",
    "    print(\"\\nVariance:\")\n",
    "    print(variance)\n",
    "    print(\"\\n----------------------------------------------------------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07b17355-a670-489b-8c4f-6d1f54f6bc43",
   "metadata": {},
   "source": [
    "#### Outliers were excluding using IQR earlier, so it was omitted from this analysis. The raw data is basically useless due to noisy data. Correlation is generally highest magnitude with odometer, transimission, and sometimes cylinders. Price has the highest varaince followed by odometer, price and year. Covariance is high for odometer and model. Covariance is not as high but still moderate for year and cylinders. Standard deviation for price and odometer are fairly large numbers and are consistent through the data sets. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cba848ff-1931-4655-a606-12fd1f1c9095",
   "metadata": {},
   "source": [
    "## Scatterplots for relationship between quantitative variables and car prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "983c7350-2c73-4950-bea6-c8c05c1cbc41",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting up a scatter plot between the year and the price\n",
    "fig, ax = plt.subplots()\n",
    "year = newUsedCars[\"year\"]\n",
    "price = newUsedCars[\"price\"]\n",
    "ax.scatter(year, price)\n",
    "\n",
    "# Creating a regression line to show the trend\n",
    "\n",
    "m, b = np.polyfit(year, price, deg=1)\n",
    "ax.plot(year, m * year + b, color=\"red\")\n",
    "\n",
    "#labels\n",
    "plt.xlabel(\"Year\")\n",
    "plt.ylabel(\"Price (Dollars)\")\n",
    "\n",
    "# setting the limits to make it easy to view\n",
    "plt.ylim(-1000, 60000)\n",
    "plt.show()\n",
    "#plt.xlim(1900, 2022)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e418ac3-233f-4a1f-8c2e-aa516711be03",
   "metadata": {},
   "source": [
    "#### Looking at this graph, there seems to be a slightly positive relationship between the year and the price. There is a strong positve linear relationship between the age of a car and its price, showing that age is a good indicator of price and a valuable input for our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "574996b5-a4a2-485b-ad85-37c505cf0104",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting up a scatter plot between the mileage and the price\n",
    "fig, ax = plt.subplots()\n",
    "mileage = newUsedCars[\"odometer\"]\n",
    "price = newUsedCars[\"price\"]\n",
    "\n",
    "#plotting the line\n",
    "ax.scatter(mileage, price)\n",
    "\n",
    "# Creating a regression line to show the trend\n",
    "m, b = np.polyfit(mileage, price, deg=1)\n",
    "ax.plot(mileage, m * mileage + b, color=\"red\")\n",
    "\n",
    "#labels\n",
    "plt.xlabel(\"Mileage (Miles)\")\n",
    "plt.ylabel(\"Price (Dollars)\")\n",
    "\n",
    "# setting the limits to make it easy to view\n",
    "plt.ylim(-1000, 60000)\n",
    "plt.xlim(-5000, 300000)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a60e2ae-da13-4296-bfc1-ca5ba3e32c57",
   "metadata": {},
   "source": [
    "#### Unlike the relationship between the year and the price, the relationship between the mileage of a car and its price is negative, meaning that the more a car has been driven, the lower its price becomes. The strongly downward sloping nature of the regression line means mileage is a valuable metric to judge a car's price"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c77f73c-a8fb-4616-afa1-5d01fb6480cd",
   "metadata": {},
   "source": [
    "## Heat Map of Correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8060bd49-6d2b-4387-863f-a2cbd52cbe83",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Correlating each relevant category with others\n",
    "correlations = newUsedCars[[\"price\", \"year\", \"odometer\", \"conditionint\", \"title_statusint\", \"transmissionint\", \"manufacturerint\", \"cylindersint\", \"driveint\", \"typeint\"]].corr()\n",
    "#Setting the axes up (Transm. = Transmission and Manuf. = Manufacturer, reduced to avoid word overlap)\n",
    "ax = plt.axes()\n",
    "ax.set_xticks([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
    "ax.set_xticklabels([\"Price\", \"Year\", \"Mileage\", \"Condition\", \"Status\", \"Transm.\", \"Manuf.\", \"Cylinders\", \"Drive\", \"Type\"], fontsize = 6)\n",
    "ax.set_yticks([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
    "ax.set_yticklabels([\"Price\", \"Year\", \"Mileage\", \"Condition\", \"Status\", \"Transm.\", \"Manuf.\", \"Cylinders\", \"Drive\", \"Type\"], fontsize = 6)\n",
    "\n",
    "#Setting the title\n",
    "plt.title(\"Correlations between selected inputs and price\")\n",
    "plt.imshow(correlations, cmap=\"winter\")\n",
    "plt.colorbar()\n",
    "#Putting the actual correlation coefficients with their respective correlation\n",
    "for i in range(10):\n",
    "    for j in range(10):\n",
    "        plt.annotate(str(round(correlations.values[i][j], 3)), xy=(j - 0.225, i), fontsize=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f76579a3-8222-4bf1-8090-4ae7b224986a",
   "metadata": {},
   "source": [
    "#### The correlation matrix shows which inputs have the most impact on price and, as a result, which inputs will be the most valuable to improving our dataset. Variables with a higher absolute correlation, like the Year and Mileage, have a far greater impact on predictions than less correlative variables like the Status and Manufacturer of the car"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "136ffc54-477e-4fcb-9081-35981c2e8f24",
   "metadata": {},
   "source": [
    "## Box Plot for price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29486caf-5f7c-4c4d-8e62-29a01d4a1f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "newUsedCars.boxplot(column=[\"price\"], vert=False, xlabel=\"Price (in millions)\")\n",
    "plt.title(\"Boxplot for the price of used cars\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61be2500-df40-480d-a94e-3e3458f4abf5",
   "metadata": {},
   "source": [
    "#### As shown by the boxplot, when major outliers are removed from the data set, the price of most cars tends to sit in the 10,000 to 20,000 dollar range. The data is somewhat skewed right, but not to a troubling extent that can get in the way of accurate testing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "429cd9f9-77ad-4e1f-8bea-d550f24b6a49",
   "metadata": {},
   "source": [
    "# Model Creation and Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0e21a1b-9123-4807-8d1f-d17452b20697",
   "metadata": {},
   "source": [
    "# -------------------------Polynomial Regression (Roshan)------------------------------\n",
    "#### For my progression, I initially started with both a Quadratic and Cubic model which tested the 2 original inputs, the year and mileage, then the four best inputs (year, mileage, transmission, number of cylinders), and finally all inputs. Throughout my progress, I compared and contrasted the accuracy between both the models while seeing the rate at which each model developed and improved. The testing for Polynomial Regression is split into the Quadratic and Cubic model, with each model split into three with the different set of inputs used for each model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4865071e-c528-412d-90d2-ed911c002a74",
   "metadata": {},
   "source": [
    "### Two Original Inputs - Quadratic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6352a819-bfbc-4ec9-964f-daa8610fc9d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The inputs to predict the price\n",
    "Inputs = newUsedCars[[\"year\", \"odometer\"]]\n",
    "#Price, the output\n",
    "Price = newUsedCars[\"price\"]\n",
    "#Splitting the dataset into 80% training and 20% testing\n",
    "trainerX, testerX, trainerY, testerY = train_test_split(Inputs, Price, test_size=0.2, random_state=27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d21f125d-9dda-44a2-8ce7-78c0b9696e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Quadratic Regression Model\n",
    "\n",
    "PolyRegress = PolynomialFeatures(2)\n",
    "polyFTrainer = PolyRegress.fit_transform(trainerX)\n",
    "polyFTester = PolyRegress.fit_transform(testerX)\n",
    "polyM = linear_model.LinearRegression()\n",
    "polyM.fit(polyFTrainer, trainerY)\n",
    "trainerYPredictions = polyM.predict(polyFTrainer)\n",
    "testerYPredictions = polyM.predict(polyFTester)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d518431e-2f2e-48ab-a904-998f9265b549",
   "metadata": {},
   "source": [
    "#### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d03cce0-b41e-4d51-ba42-4f99ce5da022",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Root mean squared error: {root_mean_squared_error(testerY, testerYPredictions)}')\n",
    "print(f'Mean absolute error: {mean_absolute_error(testerY, testerYPredictions)}')\n",
    "print(f'R-Squared: {r2_score(testerY, testerYPredictions)}')\n",
    "print(f'Relative absolute error: {relative_absolute_error(testerY, testerYPredictions)}')\n",
    "print(f'Correlation Coefficients: {polyM.coef_}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2d8b35c-09e7-4caa-8e02-f7900ab88183",
   "metadata": {},
   "source": [
    "### Four Best Inputs - Quadratic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1810b3f-92f7-4e11-9751-0a8cecadd176",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The inputs to predict the price\n",
    "Inputs = newUsedCars[[\"year\", \"odometer\", \"transmissionint\", \"cylindersint\"]]\n",
    "#Price, the output\n",
    "Price = newUsedCars[\"price\"]\n",
    "#Splitting the dataset into 80% training and 20% testing\n",
    "trainerX, testerX, trainerY, testerY = train_test_split(Inputs, Price, test_size=0.2, random_state=27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ee9ab49-381d-48ef-81fa-d98b23268e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Quadratic Regression Model\n",
    "\n",
    "PolyRegress = PolynomialFeatures(2)\n",
    "polyFTrainer = PolyRegress.fit_transform(trainerX)\n",
    "polyFTester = PolyRegress.fit_transform(testerX)\n",
    "polyM = linear_model.LinearRegression()\n",
    "polyM.fit(polyFTrainer, trainerY)\n",
    "trainerYPredictions = polyM.predict(polyFTrainer)\n",
    "testerYPredictions = polyM.predict(polyFTester)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ce333b8-fb22-4cc6-90ba-effc66291e8f",
   "metadata": {},
   "source": [
    "#### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "174dfbf9-24a0-4f0e-9144-4477c485bc5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Root mean squared error: {root_mean_squared_error(testerY, testerYPredictions)}')\n",
    "print(f'Mean absolute error: {mean_absolute_error(testerY, testerYPredictions)}')\n",
    "print(f'R-Squared: {r2_score(testerY, testerYPredictions)}')\n",
    "print(f'Relative absolute error: {relative_absolute_error(testerY, testerYPredictions)}')\n",
    "print(f'Correlation Coefficients: {polyM.coef_}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22927b62-599a-42e5-9b90-80d9e31c6344",
   "metadata": {},
   "source": [
    "### All Inputs - Quadratic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8866e779-1a31-4baa-b7fc-1ec6f1d905c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The inputs to predict the price\n",
    "Inputs = newUsedCars[[\"year\", \"odometer\", \"conditionint\", \"title_statusint\", \"transmissionint\", \"manufacturerint\", \"cylindersint\", \"driveint\", \"typeint\"]]\n",
    "#Price, the output\n",
    "Price = newUsedCars[\"price\"]\n",
    "#Splitting the dataset into 80% training and 20% testing\n",
    "trainerX, testerX, trainerY, testerY = train_test_split(Inputs, Price, test_size=0.2, random_state=27)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb9d982e-5ed9-4d0a-8c75-84e8a74f025b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Quadratic Regression Model\n",
    "\n",
    "PolyRegress = PolynomialFeatures(2)\n",
    "polyFTrainer = PolyRegress.fit_transform(trainerX)\n",
    "polyFTester = PolyRegress.fit_transform(testerX)\n",
    "polyM = linear_model.LinearRegression()\n",
    "polyM.fit(polyFTrainer, trainerY)\n",
    "trainerYPredictions = polyM.predict(polyFTrainer)\n",
    "testerYPredictions = polyM.predict(polyFTester)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "926183ef-2180-45f6-8894-812d6d087456",
   "metadata": {},
   "source": [
    "#### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea78e62-f516-4baf-9cc4-62c3629f374d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Root mean squared error: {root_mean_squared_error(testerY, testerYPredictions)}')\n",
    "print(f'Mean absolute error: {mean_absolute_error(testerY, testerYPredictions)}')\n",
    "print(f'R-Squared: {r2_score(testerY, testerYPredictions)}')\n",
    "print(f'Relative absolute error: {relative_absolute_error(testerY, testerYPredictions)}')\n",
    "print(f'Correlation Coefficients: {polyM.coef_}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cdb87d8-0129-4ad3-9db8-b9f316842c5e",
   "metadata": {},
   "source": [
    "### Two Original Inputs - Cubic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef60716b-9cde-4e6b-8a1e-8f1eaea7582c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The inputs to predict the price\n",
    "Inputs = newUsedCars[[\"year\", \"odometer\"]]\n",
    "#Price, the output\n",
    "Price = newUsedCars[\"price\"]\n",
    "#Splitting the dataset into 80% training and 20% testing\n",
    "trainerX, testerX, trainerY, testerY = train_test_split(Inputs, Price, test_size=0.2, random_state=27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8f1b8ec-d72b-4a96-9c63-d19998f655b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Cubic Regression Model\n",
    "\n",
    "PolyRegress = PolynomialFeatures(3)\n",
    "polyFTrainer = PolyRegress.fit_transform(trainerX)\n",
    "polyFTester = PolyRegress.fit_transform(testerX)\n",
    "polyM = linear_model.LinearRegression()\n",
    "polyM.fit(polyFTrainer, trainerY)\n",
    "trainerYPredictions = polyM.predict(polyFTrainer)\n",
    "testerYPredictions = polyM.predict(polyFTester)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7410d9a8-3c7e-4cb7-95ce-5524d69becc5",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c11a240d-fa8c-4e9b-9d63-62cda4da718e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Root mean squared error: {root_mean_squared_error(testerY, testerYPredictions)}')\n",
    "print(f'Mean absolute error: {mean_absolute_error(testerY, testerYPredictions)}')\n",
    "print(f'R-Squared: {r2_score(testerY, testerYPredictions)}')\n",
    "print(f'Relative absolute error: {relative_absolute_error(testerY, testerYPredictions)}')\n",
    "print(f'Correlation Coefficients: {polyM.coef_}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42fc15d8-94b0-4127-9226-82973bea873c",
   "metadata": {},
   "source": [
    "### Four Best Inputs - Cubic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1c1d2c9-141f-4e57-9aae-75b28c5b9ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The inputs to predict the price\n",
    "Inputs = newUsedCars[[\"year\", \"odometer\", \"transmissionint\", \"cylindersint\"]]\n",
    "#Price, the output\n",
    "Price = newUsedCars[\"price\"]\n",
    "#Splitting the dataset into 80% training and 20% testing\n",
    "trainerX, testerX, trainerY, testerY = train_test_split(Inputs, Price, test_size=0.2, random_state=27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35390e30-8c07-4438-b78a-846fe8241a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Cubic Regression Model\n",
    "\n",
    "PolyRegress = PolynomialFeatures(3)\n",
    "polyFTrainer = PolyRegress.fit_transform(trainerX)\n",
    "polyFTester = PolyRegress.fit_transform(testerX)\n",
    "polyM = linear_model.LinearRegression()\n",
    "polyM.fit(polyFTrainer, trainerY)\n",
    "trainerYPredictions = polyM.predict(polyFTrainer)\n",
    "testerYPredictions = polyM.predict(polyFTester)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9e5010a-746f-4eed-be8d-9da0e37b140b",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89204a8a-ce2e-4371-85e8-8bb1b99af07a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Root mean squared error: {root_mean_squared_error(testerY, testerYPredictions)}')\n",
    "print(f'Mean absolute error: {mean_absolute_error(testerY, testerYPredictions)}')\n",
    "print(f'R-Squared: {r2_score(testerY, testerYPredictions)}')\n",
    "print(f'Relative absolute error: {relative_absolute_error(testerY, testerYPredictions)}')\n",
    "print(f'Correlation Coefficients: {polyM.coef_}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb1e6ee7-f2e3-40e9-a0fa-cbd2e909df9e",
   "metadata": {},
   "source": [
    "### All Inputs - Cubic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db61c827-4897-40f9-a981-fb20277f7da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The inputs to predict the price\n",
    "Inputs = newUsedCars[[\"year\", \"odometer\", \"conditionint\", \"title_statusint\", \"transmissionint\", \"manufacturerint\", \"cylindersint\", \"driveint\", \"typeint\"]]\n",
    "#Price, the output\n",
    "Price = newUsedCars[\"price\"]\n",
    "#Splitting the dataset into 80% training and 20% testing\n",
    "trainerX, testerX, trainerY, testerY = train_test_split(Inputs, Price, test_size=0.2, random_state=27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04bd0405-109e-4090-a0af-7d0419855fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Cubic Regression Model\n",
    "\n",
    "PolyRegress = PolynomialFeatures(3)\n",
    "polyFTrainer = PolyRegress.fit_transform(trainerX)\n",
    "polyFTester = PolyRegress.fit_transform(testerX)\n",
    "polyM = linear_model.LinearRegression()\n",
    "polyM.fit(polyFTrainer, trainerY)\n",
    "trainerYPredictions = polyM.predict(polyFTrainer)\n",
    "testerYPredictions = polyM.predict(polyFTester)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb0891d5-ceb6-40d1-8f72-9d74b01ff4a9",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d30cbb8-d4fb-4c41-b35d-df520945c170",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Root mean squared error: {root_mean_squared_error(testerY, testerYPredictions)}')\n",
    "print(f'Mean absolute error: {mean_absolute_error(testerY, testerYPredictions)}')\n",
    "print(f'R-Squared: {r2_score(testerY, testerYPredictions)}')\n",
    "print(f'Relative absolute error: {relative_absolute_error(testerY, testerYPredictions)}')\n",
    "print(f'Correlation Coefficients: {polyM.coef_}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d07582a5-b904-4dfd-a5f2-c951e3593535",
   "metadata": {},
   "source": [
    "## Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acc1f7fa-3b73-44b2-8e6a-d42a6debb2ce",
   "metadata": {},
   "source": [
    "* When both the Quadratic and Cubic models had very few inputs, originally only the age and mileage, they fit poorly, having an R-squared value below 0.5, but both models performed well as more inputs were added\n",
    "* Even inputs with lower correlation values can still contribute to greater accuracy, both the Quadrtaic and Cubic models improved their accuracy tremendously when they had more inputs to work with regardless of the strength of correlation\n",
    "* Neither this model nor the quadratic model ran into overfitting the training dataset, meaning both the number of inputs and the degree of the model were low enough to keep the training set as a good indicator for testing.\n",
    "* Cubic regression outperformed Quadratic regression with all inputs, and vice versa for only four inputs, calling into consideration the impacts of the degree hyperparameter\n",
    "* This could indicate that Cubic regression is better for studying a dataset with a large array of inputs than Quadratic regression, but fewer inputs would be better handled by Quadratic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d247609-9fe5-4872-9ab3-c9aa707ae294",
   "metadata": {},
   "source": [
    "\n",
    "# -------------------------------Lasso Regression (Rachel)----------------------------------------\n",
    "\n",
    "For Lasso Regression I will create two models, one with all features and one with only the features with high correlations to price.\n",
    "\n",
    "The 3 features with the most correlation are:\n",
    "\n",
    "    Mileage\n",
    "    Transmission\n",
    "    Year\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70bc6810-237f-4e8e-af10-88cb0d04131a",
   "metadata": {},
   "outputs": [],
   "source": [
    "lass = Lasso()\n",
    "lass.fit(trainerX, trainerY)\n",
    "print(lass.intercept_)\n",
    "print(lass.coef_)\n",
    "lassPredict = lass.predict(testerX)\n",
    "print(\"Score \", root_mean_squared_error(testerY, lassPredict))\n",
    "print(f'R-Squared: {r2_score(testerY, lassPredict)}')\n",
    "\n",
    "\n",
    "print()\n",
    "print()\n",
    "refinedInput = newUsedCars[[\"year\", \"odometer\",\"transmissionint\"]]\n",
    "rtrainerX, rtesterX, rtrainerY, rtesterY = train_test_split(refinedInput, Price, test_size=0.2, random_state=27)\n",
    "\n",
    "rlass = Lasso()\n",
    "rlass.fit(rtrainerX, rtrainerY)\n",
    "print(rlass.intercept_)\n",
    "print(rlass.coef_)\n",
    "rlassPredict = rlass.predict(rtesterX)\n",
    "print(\"Score \", root_mean_squared_error(rtesterY, rlassPredict))\n",
    "print(f'R-Squared: {r2_score(rtesterY, rlassPredict)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "556f7826-7259-47c4-b6a9-002116a5c07f",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "**My theory that less criterias would lead to a higher R-Squared value was wrong.**\n",
    "\n",
    "My finding with Lasso Regression is that there is a 55% accuracy with this models output. Because Lasso experiences hardly any changes when tuning is done though the changing of hyperparameters, I will not be changing the alpha in attempts to make the model more accurate.\n",
    "\n",
    "**However, improvements can be made with data scaling**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "616f95bf-e89d-4212-89ec-a85de4fbc2a0",
   "metadata": {},
   "source": [
    "# ------------Decision tree Regression (Bilal)------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b27477-fd69-419e-ab48-e7b5c3a73bf9",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "x = newUsedCars[['odometer']]\n",
    "y = newUsedCars['price']\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=27)\n",
    "RTModel = DecisionTreeRegressor(random_state=27)\n",
    "RTModel.fit(X_train, y_train)\n",
    "y_pred = RTModel.predict(X_test)\n",
    "\n",
    "print(f'Root mean squared error: {root_mean_squared_error(y_test, y_pred)}')\n",
    "print(f'Mean absolute error: {mean_absolute_error(y_test, y_pred)}')\n",
    "print(f'R-Squared: {r2_score(y_test, y_pred)}')\n",
    "print(f'Relative absolute error: {relative_absolute_error(y_test, y_pred)}')\n",
    "print(f'Correlation Coefficients: {RTModel.feature_importances_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13648107-0226-44bd-914d-46c48741d642",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "x = newUsedCars[['odometer', 'year', 'modelint']]\n",
    "y = newUsedCars['price']\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=27)\n",
    "RTModel = DecisionTreeRegressor(random_state=27)\n",
    "RTModel.fit(X_train, y_train)\n",
    "y_pred = RTModel.predict(X_test)\n",
    "\n",
    "print(f'Root mean squared error: {root_mean_squared_error(y_test, y_pred)}')\n",
    "print(f'Mean absolute error: {mean_absolute_error(y_test, y_pred)}')\n",
    "print(f'R-Squared: {r2_score(y_test, y_pred)}')\n",
    "print(f'Relative absolute error: {relative_absolute_error(y_test, y_pred)}')\n",
    "print(f'Correlation Coefficients: {RTModel.feature_importances_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b972b44-fdb6-42d5-be29-012abdddc927",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "x = newUsedCars[['odometer', 'year', 'modelint', 'transmissionint', 'manufacturerint']]\n",
    "y = newUsedCars['price']\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=27)\n",
    "RTModel = DecisionTreeRegressor(random_state=27)\n",
    "RTModel.fit(X_train, y_train)\n",
    "y_pred = RTModel.predict(X_test)\n",
    "\n",
    "print(f'Root mean squared error: {root_mean_squared_error(y_test, y_pred)}')\n",
    "print(f'Mean absolute error: {mean_absolute_error(y_test, y_pred)}')\n",
    "print(f'R-Squared: {r2_score(y_test, y_pred)}')\n",
    "print(f'Relative absolute error: {relative_absolute_error(y_test, y_pred)}')\n",
    "print(f'Correlation Coefficients: {RTModel.feature_importances_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31f651db-7601-4b63-95f5-0a81382b52f8",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "x = newUsedCars[['odometer', 'year', 'modelint', 'transmissionint', 'manufacturerint', 'cylindersint']]\n",
    "y = newUsedCars['price']\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=27)\n",
    "RTModel = DecisionTreeRegressor( random_state=27)\n",
    "RTModel.fit(X_train, y_train)\n",
    "y_pred = RTModel.predict(X_test)\n",
    "\n",
    "print(f'Root mean squared error: {root_mean_squared_error(y_test, y_pred)}')\n",
    "print(f'Mean absolute error: {mean_absolute_error(y_test, y_pred)}')\n",
    "print(f'R-Squared: {r2_score(y_test, y_pred)}')\n",
    "print(f'Relative absolute error: {relative_absolute_error(y_test, y_pred)}')\n",
    "print(f'Correlation Coefficients: {RTModel.feature_importances_}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63f769cd-4d1f-4c9f-9548-db97223ea4e3",
   "metadata": {},
   "source": [
    "#### The decision tree regression model performed quite well on the data set. As more input features were added the performance increased quite a lot. The decision tree regression model is quite suitable for this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ca0b11e-3461-411b-b794-a74385792b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = newUsedCars[['odometer', 'year', 'modelint', 'transmissionint', 'manufacturerint', 'cylindersint', 'driveint']]\n",
    "y = newUsedCars['price']\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=27)\n",
    "RTModel = DecisionTreeRegressor(random_state=27)\n",
    "RTModel.fit(X_train, y_train)\n",
    "y_pred = RTModel.predict(X_test)\n",
    "\n",
    "print(f'Root mean squared error: {root_mean_squared_error(y_test, y_pred)}')\n",
    "print(f'Mean absolute error: {mean_absolute_error(y_test, y_pred)}')\n",
    "print(f'R-Squared: {r2_score(y_test, y_pred)}')\n",
    "print(f'Relative absolute error: {relative_absolute_error(y_test, y_pred)}')\n",
    "print(f'Correlation Coefficients: {RTModel.feature_importances_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75a81fd2-2a6e-41b5-9668-d2ac8bd500c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = newUsedCars[['odometer', 'year', 'modelint', 'transmissionint', 'manufacturerint', 'cylindersint', 'driveint']]\n",
    "y = newUsedCars['price']\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=27)\n",
    "RTModel = DecisionTreeRegressor(max_depth=26, min_samples_split=18, min_samples_leaf=9,random_state=27)\n",
    "RTModel.fit(X_train, y_train)\n",
    "y_pred = RTModel.predict(X_test)\n",
    "            \n",
    "print(f'Root mean squared error: {root_mean_squared_error(y_test, y_pred)}')\n",
    "print(f'Mean absolute error: {mean_absolute_error(y_test, y_pred)}')\n",
    "print(f'R-Squared: {r2_score(y_test, y_pred)}')\n",
    "print(f'Relative absolute error: {relative_absolute_error(y_test, y_pred)}')\n",
    "print(f'Correlation Coefficients: {RTModel.feature_importances_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5adb6a1-c7c3-4c01-8cec-21a91254e459",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = usedDealerShips[['odometer', 'year','modelint', 'transmissionint', 'manufacturerint',  \"cylindersint\"]]\n",
    "y = usedDealerShips['price']\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=27)\n",
    "RTModel = DecisionTreeRegressor(max_depth=23, min_samples_split=27, min_samples_leaf=5, random_state=27)\n",
    "RTModel.fit(X_train, y_train)\n",
    "y_pred = RTModel.predict(X_test)\n",
    "\n",
    "print(f'Root mean squared error: {root_mean_squared_error( y_test, y_pred)}')\n",
    "print(f'Mean absolute error: {mean_absolute_error(y_test, y_pred)}')\n",
    "print(f'R-Squared: {r2_score(y_test, y_pred)}')\n",
    "print(f'Relative absolute error: {relative_absolute_error(y_test, y_pred)}')\n",
    "print(f'Correlation Coefficients: {RTModel.feature_importances_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42c02f67-fe2f-4f9a-a9d8-f223bc712913",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = vehicles[['odometer', 'year','modelint', 'transmissionint', 'manufacturerint']]\n",
    "y = vehicles['price']\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=27)\n",
    "RTModel = DecisionTreeRegressor(max_depth=23, min_samples_split=23, min_samples_leaf=7,random_state=27)\n",
    "RTModel.fit(X_train, y_train)\n",
    "y_pred = RTModel.predict(X_test)\n",
    "print(f'Root mean squared error: {root_mean_squared_error( y_test, y_pred)}')\n",
    "print(f'Mean absolute error: {mean_absolute_error(y_test, y_pred)}')\n",
    "print(f'R-Squared: {r2_score(y_test, y_pred)}')\n",
    "print(f'Relative absolute error: {relative_absolute_error(y_test, y_pred)}')\n",
    "print(f'Correlation Coefficients: {RTModel.feature_importances_}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "357e33c8-20c9-4f65-8596-cb647b1424ee",
   "metadata": {},
   "source": [
    "#### When compared between the 3 datasets with different preprocessing, it performed the best on the data set where no distinction was made between independent sellers and dealerships. The data set where it performed the best was also the dataset where duplicate descriptions were not removed which could be a factor on why predictive modeling is better on the dataset. The dataset with entries that are likely from dealerships performed better than the dataset with independent sellers. This can indicate that the dealerships use the input features in their pricing decisions to a larger extent."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e497bc3-6d05-47fd-82dd-de03eb4edc7e",
   "metadata": {},
   "source": [
    "# ---------------------------------------------Multiple Linear Regression (Sai)----------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5870ffe5-2948-493c-823d-d7515f930563",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features and target variable\n",
    "x = newUsedCars[['odometer', 'year', 'modelint', 'transmissionint', 'manufacturerint', 'cylindersint', 'driveint']]\n",
    "y = newUsedCars['price']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eae467b3-b13a-4edd-aa32-2c341eabb6b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=27)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3e628a5-41b6-4498-aee3-cce064456b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the multiple regression model\n",
    "multi_reg_model = LinearRegression()\n",
    "\n",
    "# Train the model\n",
    "multi_reg_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = multi_reg_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e3c1f10-6d06-43c2-8353-c42bcd8ee6cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define relative absolute error function\n",
    "def relative_absolute_error(y_true, y_pred):\n",
    "    return np.sum(np.abs(y_pred - y_true)) / np.sum(np.abs(y_true - np.mean(y_true)))\n",
    "\n",
    "# Compute metrics\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "rae = relative_absolute_error(y_test, y_pred)\n",
    "\n",
    "# Print the evaluation metrics\n",
    "print(f'Root Mean Squared Error: {rmse}')\n",
    "print(f'Mean Absolute Error: {mae}')\n",
    "print(f'R-Squared: {r2}')\n",
    "print(f'Relative Absolute Error: {rae}')\n",
    "\n",
    "# Print the coefficients of the model\n",
    "print('Coefficients:')\n",
    "print(dict(zip(x.columns, multi_reg_model.coef_)))\n",
    "#  Visualize actual vs predicted prices\n",
    "plt.scatter(y_test, y_pred)\n",
    "plt.xlabel('Actual Prices')\n",
    "plt.ylabel('Predicted Prices')\n",
    "plt.title('Actual vs Predicted Car Prices')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.barh(x.columns, multi_reg_model.coef_)\n",
    "plt.xlabel('Coefficient Value')\n",
    "plt.ylabel('Features')\n",
    "plt.title('Feature Importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e98d936-eb72-4fdd-ad7e-563effcbc107",
   "metadata": {},
   "source": [
    "### The odometer reading has a negative coefficient of approximately -0.049, indicating that higher mileage typically decreases the car's price, as expected due to increased wear and tear. Conversely, the year of manufacture shows a positive coefficient of around 766.29, suggesting that newer cars command higher prices, which aligns with the perception that newer models are more desirable. Although the model number (encoded as modelint) has a very small positive coefficient, its impact on price is minimal. The transmission type (encoded as transmissionint) has a substantial positive coefficient of about 3785.77, highlighting that certain types of transmission, such as automatic, may significantly increase a car's value. The manufacturer's encoding also has a positive effect on price, albeit relatively small, with a coefficient of 38.84, reflecting slight variations in value based on brand reputation. The number of cylinders in the car's engine, with a coefficient of approximately 3111.19, suggests that cars with more cylinders, and therefore potentially higher performance, tend to have higher prices. Lastly, the drive type (encoded as driveint) has a negative coefficient of -933.26, implying that some drive types may reduce the car's price, possibly due to less favorable buyer preferences. These insights help us understand the relative importance of each feature in determining the price of a used car and guide future model improvements and data analyses."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d7cf156-57e6-40cc-baf0-24e0a5287dd5",
   "metadata": {},
   "source": [
    "#### Potential Improvements\n",
    "Seeing as how the 3 most important features are cylinders, transmission, and year; we should train the model using those three params to further progress this model.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcb6f760-05df-48c7-9790-be37145b04ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features and target variable\n",
    "x = newUsedCars[[ 'year', 'transmissionint',  'cylindersint']]\n",
    "y = newUsedCars['price']\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=27)\n",
    "# Initialize the multiple regression model\n",
    "multi_reg_model = LinearRegression()\n",
    "\n",
    "# Train the model\n",
    "multi_reg_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = multi_reg_model.predict(X_test)\n",
    "# Define relative absolute error function\n",
    "def relative_absolute_error(y_true, y_pred):\n",
    "    return np.sum(np.abs(y_pred - y_true)) / np.sum(np.abs(y_true - np.mean(y_true)))\n",
    "\n",
    "# Compute metrics\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "rae = relative_absolute_error(y_test, y_pred)\n",
    "\n",
    "# Print the coefficients of the model\n",
    "print('Coefficients:')\n",
    "print(dict(zip(x.columns, multi_reg_model.coef_)))\n",
    "#  Visualize actual vs predicted prices\n",
    "plt.scatter(y_test, y_pred)\n",
    "plt.xlabel('Actual Prices')\n",
    "plt.ylabel('Predicted Prices')\n",
    "plt.title('Actual vs Predicted Car Prices')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1153c7dd-280a-4cdf-a7d1-fc8b5740083d",
   "metadata": {},
   "source": [
    "# Ridge Regression (Michael)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9931dad6-6f1c-49d2-9e6c-ea3e2bbc48fa",
   "metadata": {},
   "source": [
    "I will create and evaluate 3 models using Ridge Regression:\n",
    "1. Year, odometer, manufactureint\n",
    "2. Year, odometer, conditionint, driveint\n",
    "3. All inputs\n",
    "\n",
    "With these inputs varying, I hope to achieve some pattern to further understand the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44b1ad98-45f0-4cf6-af7f-defe9cceee84",
   "metadata": {},
   "source": [
    "# Year, odometer, manufactureint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9511f53e-0a30-4eaf-b764-d19d45567b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "# Inputs (our X) are year, odometer, and conditionint in dataset\n",
    "Inputs_1 = newUsedCars[[\"year\", \"odometer\", \"manufacturerint\"]]\n",
    "\n",
    "# Splitting dataset into training and testing\n",
    "train_X_1, test_X_1, train_y_1, test_y_1 = train_test_split(\n",
    "    Inputs_1, Price, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Scaled to normalize\n",
    "scaler_1 = StandardScaler()\n",
    "trainX_1_scaled = scaler_1.fit_transform(train_X_1)\n",
    "testX_1_scaled = scaler_1.transform(test_X_1)\n",
    "\n",
    "# Ridge reg step\n",
    "ridge_1 = Ridge(alpha=1.0)\n",
    "ridge_1.fit(trainX_1_scaled, train_y_1)\n",
    "pred_y_1 = ridge_1.predict(testX_1_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54d85c03-acce-4577-9a12-ab7307f607b8",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df408e4f-1ab9-475e-a097-480149f9bb83",
   "metadata": {},
   "outputs": [],
   "source": [
    "r_square_1 = r2_score(test_y_1, pred_y_1)\n",
    "mean_absolute_1 = mean_absolute_error(test_y_1, pred_y_1)\n",
    "root_mean_square_1 = np.sqrt(mean_squared_error(test_y_1, pred_y_1))\n",
    "correlation_1 = np.corrcoef(test_y_1, pred_y_1)[0, 1]\n",
    "relative_absolute_error_1 = (np.sum(np.abs(test_y_1 - pred_y_1)) /np.sum(np.abs(test_y_1 - np.mean(test_y_1))))\n",
    "\n",
    "print(\"Model 1 with `year`, `odometer`, and `manufacturerint`:\")\n",
    "print(\"R-squared:\", r_square_1)\n",
    "print(\"Mean Absolute Error:\", mean_absolute_1)\n",
    "print(\"Root Mean Squared Error:\", root_mean_square_1)\n",
    "print(\"Correlation Coefficient:\", correlation_1)\n",
    "print(\"Relative Absolute Error:\", relative_absolute_error_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "922d080b-4c22-4261-a277-f5f59436a7cf",
   "metadata": {},
   "source": [
    "# Year, odometer, conditionint, driveint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d63a82a-6196-4f33-a15d-ec384fccc24a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inputs (our X) are year, odometer, conditionint, and driveint in dataset\n",
    "Inputs_2 = newUsedCars[[\"year\", \"odometer\", \"conditionint\", \"driveint\"]]\n",
    "\n",
    "# Splitting dataset into training and testing\n",
    "train_X_2, test_X_2, train_y_2, test_y_2 = train_test_split(\n",
    "    Inputs_2, Price, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Scaled to normalize\n",
    "scaler_2 = StandardScaler()\n",
    "trainX_2_scaled = scaler_2.fit_transform(train_X_2)\n",
    "testX_2_scaled = scaler_2.transform(test_X_2)\n",
    "\n",
    "# Ridge reg step\n",
    "ridge_2 = Ridge(alpha=1.0)\n",
    "ridge_2.fit(trainX_2_scaled, train_y_2)\n",
    "pred_y_2 = ridge_2.predict(testX_2_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9661e2e9-a627-4f73-be12-48795ecbe267",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05ac24ca-13f9-4bb4-bb04-f106ef611546",
   "metadata": {},
   "outputs": [],
   "source": [
    "r_square_2 = r2_score(test_y_2, pred_y_2)\n",
    "mean_absolute_2 = mean_absolute_error(test_y_2, pred_y_2)\n",
    "root_mean_square_2 = np.sqrt(mean_squared_error(test_y_2, pred_y_2))\n",
    "correlation_2 = np.corrcoef(test_y_2, pred_y_2)[0, 1]\n",
    "relative_absolute_error_2 = (np.sum(np.abs(test_y_2 - pred_y_2)) /np.sum(np.abs(test_y_2 - np.mean(test_y_2))))\n",
    "\n",
    "print(\"Model 2 with `year`, `odometer`, `conditionint`, and `driveint`:\")\n",
    "print(\"R-squared:\", r_square_2)\n",
    "print(\"Mean Absolute Error:\", mean_absolute_2)\n",
    "print(\"Root Mean Squared Error:\", root_mean_square_2)\n",
    "print(\"Correlation Coefficient:\", correlation_2)\n",
    "print(\"Relative Absolute Error:\", relative_absolute_error_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b914d3e1-0a67-44e2-adfb-5e8f5e87e79c",
   "metadata": {},
   "source": [
    "# All inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc2ae367-95cf-4b73-9405-e8168c0fe6cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inputs (our X) is all inputs in dataset\n",
    "Inputs = newUsedCars[[\"year\", \"manufacturerint\", \"conditionint\", \"cylindersint\", \"odometer\",\n",
    "                 \"title_statusint\", \"transmissionint\", \"driveint\", \"typeint\"]]\n",
    "\n",
    "# Our target variable, Price\n",
    "Price = newUsedCars[\"price\"]\n",
    "\n",
    "# Splitting dataset into training and testing\n",
    "train_X, test_X, train_y, test_y = train_test_split(Inputs, Price, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scaled to normalize\n",
    "scaler = StandardScaler()\n",
    "trainX_scaled = scaler.fit_transform(train_X)\n",
    "testX_scaled = scaler.transform(test_X)\n",
    "\n",
    "# Ridge reg step\n",
    "ridge = Ridge(alpha=1.0) \n",
    "ridge.fit(trainX_scaled, train_y)\n",
    "pred_y = ridge.predict(testX_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5cd2102-1f26-43e1-91d7-cd69a151421d",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff5bd936-7907-4b95-bfc5-2caba48a295a",
   "metadata": {},
   "outputs": [],
   "source": [
    "r_square = r2_score(test_y, pred_y)\n",
    "mean_absolute = mean_absolute_error(test_y, pred_y)\n",
    "root_mean_square = np.sqrt(mean_squared_error(test_y, pred_y))\n",
    "correlation = np.corrcoef(test_y, pred_y)[0, 1] \n",
    "relative_absolute_error = np.sum(np.abs(test_y - pred_y)) / np.sum(np.abs(test_y - np.mean(test_y)))\n",
    "\n",
    "print(\"Model 3 with all inputs:\")\n",
    "print(\"R-squared:\", r_square)\n",
    "print(\"Mean Absolute Error:\", mean_absolute)\n",
    "print(\"Root Mean Squared Error:\", root_mean_square)\n",
    "print(\"Correlation Coefficient:\", correlation)\n",
    "print(\"Relative Absolute Error:\", relative_absolute_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95a08854-7b96-46ab-a80f-5a78b23af0bd",
   "metadata": {},
   "source": [
    "## Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6b6c0b4-fbe1-4fdd-879c-61898d581739",
   "metadata": {},
   "source": [
    "* For model 1, we have relatively high MAE and RMSE, so this model was middling in terms of accuracy\n",
    "* The coefficient of 0.614 in model 1 shows a moderate positive relationship between the predictions and target.\n",
    "* For model 2, the R-squared value improved slightly, as well as the MAE and RMSE values being lower.\n",
    "* Additionally, the coefficient is slightly higher.\n",
    "* Finally, when looking at the model with all inputs, R-squared improves greatly, as well as the MAE and RMSE being much lower, which indicates better accuracy.\n",
    "* Also, the coefficient improves to 0.742, showing a positive relationship."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "186cf5dd-e01e-4935-9076-60dd4bb7316d",
   "metadata": {},
   "source": [
    "Overall, in my exploration with Ridge Regression, I found that the model with all inputs should be used when making predictions because it provides the most accurate results."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
