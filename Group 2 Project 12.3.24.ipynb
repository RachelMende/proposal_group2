{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4fb629f9-c1c8-40b2-88a3-eb5133c9c899",
   "metadata": {},
   "source": [
    "# Group 2 Project: Used Cars"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e55aec9c-86c0-4234-a40e-685e605121c5",
   "metadata": {},
   "source": [
    "## Description to run the notebook:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38aa9fb3-4b4b-4ae7-9efa-078cbd1ab9a2",
   "metadata": {},
   "source": [
    "### After downloading the vehicles.csv file, the file needs to be put into the same folder which holds our project (and have the name \"vehicles.csv\"). Our csv reader assumes that the file is directly accessible from the same folder, and needs to see it, otherwise it'll throw an error. From there, all cells can be ran as normal. (NOTE: Our dataset has approximately 450,000 entries, so the file is 1.4 Gigabytes and will take some time to upload to jupyter lab and read)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "46e445e0-48af-40c4-b299-302d8bab4d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import pandas as pd\n",
    "from typing import List\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.metrics import root_mean_squared_error, r2_score, mean_absolute_error\n",
    "#Creating a function to collect the relative absolute error\n",
    "def relative_absolute_error(a, b):\n",
    "    meanabs = mean_absolute_error(a, b)\n",
    "    a_mean = np.mean(a)\n",
    "    return meanabs/(mean_absolute_error(a, np.full(a.shape, a_mean)))\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import Lasso\n",
    "from typing import Dict\n",
    "import csv\n",
    "from typing import NamedTuple\n",
    "from scipy.spatial import distance\n",
    "from collections import defaultdict\n",
    "from sklearn import metrics\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "Vector = List[float]\n",
    "pd.options.mode.chained_assignment = None "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "523dded5-0914-472f-8f18-a2ff18c64a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The car dataset in its original form before any testing\n",
    "original = pd.read_csv(\"vehicles.csv\", engine = \"python\", encoding = \"latin1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b12aea69-22d0-45f8-bfd5-8f54133028a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#########\n",
    "#Extracting the input features from the original dataset\n",
    "usedcars = original[[\"price\", \"year\", \"manufacturer\", \"condition\", \"cylinders\", \"odometer\", \"title_status\", \"transmission\", \"drive\", \"type\", \"model\"]]\n",
    "#########"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18a0e267-8bef-418e-afbd-70df7d2cbfaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Consider only values which don't have a null value\n",
    "newUsedCars = usedcars.dropna()\n",
    "\n",
    "#Find outliers within the dataset to reduce extremeities and skewness\n",
    "def find_outliers_iqr(df, column):\n",
    "    q1 = df[column].quantile(0.25)\n",
    "    q3 = df[column].quantile(0.75)\n",
    "    iqr = q3 - q1\n",
    "    lower_bound = q1 - 1.5 * iqr\n",
    "    upper_bound = q3 + 1.5 * iqr\n",
    "    df.drop(df[(df[column] < lower_bound)].index, inplace = True)\n",
    "    df.drop(df[(df[column] > upper_bound)].index, inplace = True)\n",
    "    \n",
    "find_outliers_iqr(newUsedCars, 'price')\n",
    "find_outliers_iqr(newUsedCars, 'odometer')\n",
    "find_outliers_iqr(newUsedCars, 'year')\n",
    "\n",
    "##Turns string to int value for relevant input features\n",
    "le = LabelEncoder()\n",
    "newUsedCars['conditionint'] = le.fit_transform(newUsedCars['condition'])\n",
    "newUsedCars[\"title_statusint\"] = le.fit_transform(newUsedCars[\"title_status\"])\n",
    "newUsedCars[\"transmissionint\"] = le.fit_transform(newUsedCars[\"transmission\"])\n",
    "newUsedCars[\"manufacturerint\"] = le.fit_transform(newUsedCars[\"manufacturer\"])\n",
    "newUsedCars[\"cylindersint\"] = le.fit_transform(newUsedCars[\"cylinders\"])\n",
    "newUsedCars[\"driveint\"] = le.fit_transform(newUsedCars[\"drive\"])\n",
    "newUsedCars[\"typeint\"] = le.fit_transform(newUsedCars[\"type\"])\n",
    "newUsedCars[\"modelint\"] = le.fit_transform(newUsedCars[\"model\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b4c3cbe-5889-4d3d-b63e-63ac70ce747e",
   "metadata": {},
   "source": [
    "# Data Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd635647-9e67-4bfb-a552-68ab69bbf04d",
   "metadata": {},
   "source": [
    "## Bar Charts for categorical variables and their mean prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec48897-46ce-4188-bfd2-69d4739242bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "newUsedCars.groupby([\"condition\"])[\"price\"].mean().plot(kind=\"bar\", title=\"Prices by Condition\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf50e4a7-3153-4328-8442-fe15b0ec4dd4",
   "metadata": {},
   "source": [
    "#### As seen by this graph, the mean value of a car generally decreases as its condition gets worse, though one exception are cars in \"good\" condition, which has a slightly higher mean price than the other categories. This could be the result of most of the cars in the dataset having the \"good\" condition applied to them compared to the others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e61027c-e562-4d5a-a08a-ea546385a22c",
   "metadata": {},
   "outputs": [],
   "source": [
    "newUsedCars.groupby([\"title_status\"])[\"price\"].mean().plot(kind=\"bar\", title=\"Prices by Car Status\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed3e5bea-4a8d-4e2b-8215-9f4c11c5ac79",
   "metadata": {},
   "source": [
    "#### The results from this graph are as expected, with cars that are more complete and finished being more valuable. Cars with a lien status ont hem are sold off at even higher prices than the rest, though the means are still closer together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e1806fb-8706-4dda-a599-f0ac84d94077",
   "metadata": {},
   "outputs": [],
   "source": [
    "newUsedCars.groupby([\"transmission\"])[\"price\"].mean().plot(kind=\"bar\", title=\"Prices by Transmission Type\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10830d3d-1f0e-4468-b202-dd33ca1c272b",
   "metadata": {},
   "source": [
    "#### There isn't much difference between the mean prices of the types of transmissions, though cars with alternative transmissions are more valuable overall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b8ca84-9728-4e47-be3c-e4605153ebeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "newUsedCars.groupby([\"manufacturer\"])[\"price\"].mean().plot(kind=\"bar\", title=\"Prices by Manufacturer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa53d770-9753-4ab6-96ef-e4c77ba56831",
   "metadata": {},
   "source": [
    "#### There are strong differences among the mean prices of cars by their manufacutrer. Generally more high-class manufactuers like Alfa-Romeo and Aston-Martin are far more valuable than more general car manufacturers like Chevrolet and Ford."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c5f83f-d5d4-4e2f-a4d1-b35401d46218",
   "metadata": {},
   "outputs": [],
   "source": [
    "newUsedCars.groupby([\"cylinders\"])[\"price\"].mean().plot(kind=\"bar\", title=\"Prices by Number of Cylinders\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75815e7d-5e60-4f08-8f6b-8f9d98e8e5f5",
   "metadata": {},
   "source": [
    "#### Though both 10-cylinder and 5-cylinder cars break from this trend, the mean price of a car generally increases as the number of cylinders increases giving a somewhat linear relationship between cylinders and prices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d3edf90-e129-42e6-8a34-c7fce34aeed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "newUsedCars.groupby([\"drive\"])[\"price\"].mean().plot(kind=\"bar\", title=\"Prices by Their Type of Drive\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55a91fd3-ca1c-4fcb-bd66-fa06b2bf672c",
   "metadata": {},
   "source": [
    "#### Cars which have a forward wheel drive have far lower mean prices than cars with a rear wheel or 4 wheel drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c4564d-9eef-45ad-8db8-2c1a2375d3b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "newUsedCars.groupby([\"type\"])[\"price\"].mean().plot(kind=\"bar\", title=\"Prices by the type of car\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daa75ced-1983-4b8b-90ae-b83b6e2c2b93",
   "metadata": {},
   "source": [
    "#### Mean prices differ heavily based on what type a specific car is, ranging from hatchbacks and mini-vans to coupes and pickups, the differences in types should be a good indicator of a specific car's value."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2ba33a7-6a67-41e8-8096-6cecbd3bcdf5",
   "metadata": {},
   "source": [
    "## Exploration of independent sellers vs businesses on Cragislist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0566919-2c3a-4221-8e4e-cca7d4de42ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "vehicles = original.copy() # Creating a copy to preserve the\n",
    "vehicles = vehicles.dropna(subset=['description', 'price', 'odometer', 'manufacturer', 'model']) \n",
    "find_outliers_iqr(vehicles, 'price')\n",
    "find_outliers_iqr(vehicles, 'odometer')\n",
    "find_outliers_iqr(vehicles, 'year')\n",
    "vehicles = vehicles.drop_duplicates(subset=['description'], keep='first')\n",
    "ogDf = vehicles.copy()\n",
    "carvana = vehicles[vehicles['description'].str.contains(\"Carvana\", case=False, na=False)]\n",
    "dealership = vehicles[vehicles['description'].str.contains(\"dealership\", case=False, na=False)]\n",
    "newCar =  vehicles[\n",
    "    vehicles[\"description\"].str.contains(\"new car\", case=False, na=False) &\n",
    "    ~vehicles[\"description\"].str.contains(\"like new\", case=False, na=False)\n",
    "]\n",
    "finance = vehicles[vehicles['description'].str.contains(\"financing available\", case=False, na=False)]\n",
    "\n",
    "combined_indices = newCar.index.union(carvana.index).union(finance.index).union(dealership.index)\n",
    "vehicles = vehicles.drop(combined_indices)\n",
    "vehicles = vehicles.reset_index(drop=True)\n",
    "carvana = carvana.reset_index(drop=True)\n",
    "newCar = newCar.reset_index(drop=True)\n",
    "finance = finance.reset_index(drop=True)\n",
    "dealership = dealership.reset_index(drop=True)\n",
    "usedDealerShips = pd.concat([carvana, dealership, newCar, finance], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b1221cd-d0c5-44b2-ba7b-c183a86bb707",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Dataset size (Bar duplicates and null values): {ogDf.shape[0]}\")\n",
    "print(f\"Vehicles listed by Carvana: {carvana.shape[0]}\")\n",
    "print(f\"Dealership vehicles: {dealership.shape[0]}\")\n",
    "print(f\"New cars (excluding 'like new'): {newCar.shape[0]}\")\n",
    "print(f\"Vehicles with financing available: {finance.shape[0]}\")\n",
    "print(f\"Remaining vehicles after removing combined indices: {vehicles.shape[0]}\")\n",
    "print(f\"Original dataset size: {original.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd5445fd-d7e6-49cf-8da7-2bfb39be86e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "iterable = ['price', 'odometer', 'year']\n",
    "for i in iterable:\n",
    "    plt.hist(vehicles[i], label = \"Independent sellers\", alpha=0.8)\n",
    "    plt.hist(usedDealerShips[i], label = \"Dealerships\", alpha=0.8)\n",
    "    plt.title(f'Distribution of {i}')\n",
    "    plt.xlabel(i)\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0ea7979-882b-4d16-8851-f05d97300b09",
   "metadata": {},
   "source": [
    "## The histograms for year, price, and year indicate skew. For dealerships, the distibution of year of cars is skewed left but independent sellers aren't as skewed. The distribution of odometer is also heavily skewed by dealerships but right this time instead of left. The distribution of odometer isn't heavily skewed in entries by independent sellers. In the distribution of price we see the opposite. The distribution of price in entries by independent sellers are skewed right heavily but dealerships is not skewed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4348f2db-51b3-45de-8b4e-8e5f3fc8ceb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = [vehicles, usedDealerShips, ogDf, original, newUsedCars]\n",
    "dfNames = [ 'Dataset of cars sold by independent sellers (with outliers removed, without duplicates and null values for certain features kept)',\n",
    "           'Dataset of cars sold by dealerships (with outliers removed, without duplicates and null values for certain features kept)',\n",
    "           \"Data set with both sellers (with outliers removed, without duplicates and null values for certain features kept)\",\n",
    "           \"Dataset in it's original state\",\n",
    "           \"Data set with outliers removed and all null values for all features removed\"]\n",
    "for i in dfs:\n",
    "    i['conditionint'] = le.fit_transform(i['condition'])\n",
    "    i[\"title_statusint\"] = le.fit_transform(i[\"title_status\"])\n",
    "    i[\"transmissionint\"] = le.fit_transform(i[\"transmission\"])\n",
    "    i[\"manufacturerint\"] = le.fit_transform(i[\"manufacturer\"])\n",
    "    i[\"modelint\"] = le.fit_transform(i[\"model\"])\n",
    "    i[\"cylindersint\"] = le.fit_transform(i[\"cylinders\"])\n",
    "    i[\"driveint\"] = le.fit_transform(i[\"drive\"])\n",
    "    i[\"typeint\"] = le.fit_transform(i[\"type\"])\n",
    "for df, name in zip(dfs, dfNames):\n",
    "    print(f\"\\nAnalysis for: {name}\\n\")\n",
    "\n",
    "    # Correlation matrix\n",
    "    print(\"Correlation with 'price':\")\n",
    "    correlation_matrix = df[['price', 'odometer', 'conditionint', 'title_statusint', 'transmissionint', \n",
    "                              'manufacturerint', 'cylindersint', 'driveint', 'typeint', 'modelint']].corr()\n",
    "    print(correlation_matrix['price'].sort_values(ascending=False))\n",
    "    \n",
    "    # Standard deviation\n",
    "    dev = df[['price', 'odometer', 'year', 'conditionint', 'title_statusint', 'transmissionint', \n",
    "                  'manufacturerint', 'cylindersint', 'driveint', 'typeint', 'modelint']].std()\n",
    "    print(\"\\nStandard Deviation:\")\n",
    "    print(dev)\n",
    "    \n",
    "    # Covariance matrix\n",
    "    covariance_matrix = df[['price', 'odometer', 'year', 'conditionint', 'title_statusint', 'transmissionint', \n",
    "                             'manufacturerint', 'cylindersint', 'driveint', 'typeint', 'modelint']].cov()\n",
    "    print(\"\\nCovariance with 'price':\")\n",
    "    print(covariance_matrix['price'])\n",
    "    # Variance\n",
    "    variance = df[['price', 'odometer', 'year', 'conditionint', 'title_statusint', 'transmissionint', \n",
    "                   'manufacturerint', 'cylindersint', 'driveint', 'typeint', 'modelint']].var()\n",
    "    print(\"\\nVariance:\")\n",
    "    print(variance)\n",
    "    print(\"\\n----------------------------------------------------------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07b17355-a670-489b-8c4f-6d1f54f6bc43",
   "metadata": {},
   "source": [
    "#### Outliers were excluding using IQR earlier, so it was omitted from this analysis. The raw data is basically useless due to noisy data. Correlation is generally highest magnitude with odometer, transimission, and sometimes cylinders. Price has the highest varaince followed by odometer, price and year. Covariance is high for odometer and model. Covariance is not as high but still moderate for year and cylinders. Standard deviation for price and odometer are fairly large numbers and are consistent through the data sets. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cba848ff-1931-4655-a606-12fd1f1c9095",
   "metadata": {},
   "source": [
    "## Scatterplots for relationship between quantitative variables and car prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "983c7350-2c73-4950-bea6-c8c05c1cbc41",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting up a scatter plot between the year and the price\n",
    "fig, ax = plt.subplots()\n",
    "year = newUsedCars[\"year\"]\n",
    "price = newUsedCars[\"price\"]\n",
    "ax.scatter(year, price)\n",
    "\n",
    "# Creating a regression line to show the trend\n",
    "\n",
    "m, b = np.polyfit(year, price, deg=1)\n",
    "ax.plot(year, m * year + b, color=\"red\")\n",
    "\n",
    "#labels\n",
    "plt.xlabel(\"Year\")\n",
    "plt.ylabel(\"Price (Dollars)\")\n",
    "\n",
    "# setting the limits to make it easy to view\n",
    "plt.ylim(-1000, 60000)\n",
    "plt.show()\n",
    "#plt.xlim(1900, 2022)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e418ac3-233f-4a1f-8c2e-aa516711be03",
   "metadata": {},
   "source": [
    "#### Looking at this graph, there seems to be a slightly positive relationship between the year and the price. There is a strong positve linear relationship between the age of a car and its price, showing that age is a good indicator of price and a valuable input for our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "574996b5-a4a2-485b-ad85-37c505cf0104",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting up a scatter plot between the mileage and the price\n",
    "fig, ax = plt.subplots()\n",
    "mileage = newUsedCars[\"odometer\"]\n",
    "price = newUsedCars[\"price\"]\n",
    "\n",
    "#plotting the line\n",
    "ax.scatter(mileage, price)\n",
    "\n",
    "# Creating a regression line to show the trend\n",
    "m, b = np.polyfit(mileage, price, deg=1)\n",
    "ax.plot(mileage, m * mileage + b, color=\"red\")\n",
    "\n",
    "#labels\n",
    "plt.xlabel(\"Mileage (Miles)\")\n",
    "plt.ylabel(\"Price (Dollars)\")\n",
    "\n",
    "# setting the limits to make it easy to view\n",
    "plt.ylim(-1000, 60000)\n",
    "plt.xlim(-5000, 300000)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a60e2ae-da13-4296-bfc1-ca5ba3e32c57",
   "metadata": {},
   "source": [
    "#### Unlike the relationship between the year and the price, the relationship between the mileage of a car and its price is negative, meaning that the more a car has been driven, the lower its price becomes. The strongly downward sloping nature of the regression line means mileage is a valuable metric to judge a car's price"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c77f73c-a8fb-4616-afa1-5d01fb6480cd",
   "metadata": {},
   "source": [
    "## Heat Map of Correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8060bd49-6d2b-4387-863f-a2cbd52cbe83",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Correlating each relevant category with others\n",
    "correlations = newUsedCars[[\"price\", \"year\", \"odometer\", \"conditionint\", \"title_statusint\", \"transmissionint\", \"manufacturerint\", \"cylindersint\", \"driveint\", \"typeint\"]].corr()\n",
    "#Setting the axes up (Transm. = Transmission and Manuf. = Manufacturer, reduced to avoid word overlap)\n",
    "ax = plt.axes()\n",
    "ax.set_xticks([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
    "ax.set_xticklabels([\"Price\", \"Year\", \"Mileage\", \"Condition\", \"Status\", \"Transm.\", \"Manuf.\", \"Cylinders\", \"Drive\", \"Type\"], fontsize = 6)\n",
    "ax.set_yticks([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
    "ax.set_yticklabels([\"Price\", \"Year\", \"Mileage\", \"Condition\", \"Status\", \"Transm.\", \"Manuf.\", \"Cylinders\", \"Drive\", \"Type\"], fontsize = 6)\n",
    "\n",
    "#Setting the title\n",
    "plt.title(\"Correlations between selected inputs and price\")\n",
    "plt.imshow(correlations, cmap=\"winter\")\n",
    "plt.colorbar()\n",
    "#Putting the actual correlation coefficients with their respective correlation\n",
    "for i in range(10):\n",
    "    for j in range(10):\n",
    "        plt.annotate(str(round(correlations.values[i][j], 3)), xy=(j - 0.225, i), fontsize=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f76579a3-8222-4bf1-8090-4ae7b224986a",
   "metadata": {},
   "source": [
    "#### The correlation matrix shows which inputs have the most impact on price and, as a result, which inputs will be the most valuable to improving our dataset. Variables with a higher absolute correlation, like the Year and Mileage, have a far greater impact on predictions than less correlative variables like the Status and Manufacturer of the car"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "136ffc54-477e-4fcb-9081-35981c2e8f24",
   "metadata": {},
   "source": [
    "## Box Plot for price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29486caf-5f7c-4c4d-8e62-29a01d4a1f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "newUsedCars.boxplot(column=[\"price\"], vert=False, xlabel=\"Price (in millions)\")\n",
    "plt.title(\"Boxplot for the price of used cars\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61be2500-df40-480d-a94e-3e3458f4abf5",
   "metadata": {},
   "source": [
    "#### As shown by the boxplot, when major outliers are removed from the data set, the price of most cars tends to sit in the 10,000 to 20,000 dollar range. The data is somewhat skewed right, but not to a troubling extent that can get in the way of accurate testing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "429cd9f9-77ad-4e1f-8bea-d550f24b6a49",
   "metadata": {},
   "source": [
    "# Model Creation and Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0e21a1b-9123-4807-8d1f-d17452b20697",
   "metadata": {},
   "source": [
    "# -------------------------Polynomial Regression (Roshan)------------------------------\n",
    "#### For my progression, I initially started with both a Quadratic and Cubic model which tested the 2 original inputs, the year and mileage, then the four best inputs (year, mileage, transmission, number of cylinders), and finally all inputs. Throughout my progress, I compared and contrasted the accuracy between both the models while seeing the rate at which each model developed and improved. The testing for Polynomial Regression is split into the Quadratic and Cubic model, with each model split into three with the different set of inputs used for each model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4865071e-c528-412d-90d2-ed911c002a74",
   "metadata": {},
   "source": [
    "### Two Original Inputs - Quadratic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6352a819-bfbc-4ec9-964f-daa8610fc9d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The inputs to predict the price\n",
    "Inputs = newUsedCars[[\"year\", \"odometer\"]]\n",
    "#Price, the output\n",
    "Price = newUsedCars[\"price\"]\n",
    "#Splitting the dataset into 80% training and 20% testing\n",
    "trainerX, testerX, trainerY, testerY = train_test_split(Inputs, Price, test_size=0.2, random_state=27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d21f125d-9dda-44a2-8ce7-78c0b9696e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Quadratic Regression Model\n",
    "\n",
    "PolyRegress = PolynomialFeatures(2)\n",
    "polyFTrainer = PolyRegress.fit_transform(trainerX)\n",
    "polyFTester = PolyRegress.fit_transform(testerX)\n",
    "polyM = linear_model.LinearRegression()\n",
    "polyM.fit(polyFTrainer, trainerY)\n",
    "trainerYPredictions = polyM.predict(polyFTrainer)\n",
    "testerYPredictions = polyM.predict(polyFTester)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d518431e-2f2e-48ab-a904-998f9265b549",
   "metadata": {},
   "source": [
    "#### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d03cce0-b41e-4d51-ba42-4f99ce5da022",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Root mean squared error: {root_mean_squared_error(testerYPredictions, testerY)}')\n",
    "print(f'Mean absolute error: {mean_absolute_error(testerYPredictions, testerY)}')\n",
    "print(f'R-Squared: {r2_score(testerYPredictions, testerY)}')\n",
    "print(f'Relative absolute error: {relative_absolute_error(testerYPredictions, testerY)}')\n",
    "print(f'Correlation Coefficients: {polyM.coef_}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2d8b35c-09e7-4caa-8e02-f7900ab88183",
   "metadata": {},
   "source": [
    "### Four Best Inputs - Quadratic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1810b3f-92f7-4e11-9751-0a8cecadd176",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The inputs to predict the price\n",
    "Inputs = newUsedCars[[\"year\", \"odometer\", \"transmissionint\", \"cylindersint\"]]\n",
    "#Price, the output\n",
    "Price = newUsedCars[\"price\"]\n",
    "#Splitting the dataset into 80% training and 20% testing\n",
    "trainerX, testerX, trainerY, testerY = train_test_split(Inputs, Price, test_size=0.2, random_state=27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ee9ab49-381d-48ef-81fa-d98b23268e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Quadratic Regression Model\n",
    "\n",
    "PolyRegress = PolynomialFeatures(2)\n",
    "polyFTrainer = PolyRegress.fit_transform(trainerX)\n",
    "polyFTester = PolyRegress.fit_transform(testerX)\n",
    "polyM = linear_model.LinearRegression()\n",
    "polyM.fit(polyFTrainer, trainerY)\n",
    "trainerYPredictions = polyM.predict(polyFTrainer)\n",
    "testerYPredictions = polyM.predict(polyFTester)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ce333b8-fb22-4cc6-90ba-effc66291e8f",
   "metadata": {},
   "source": [
    "#### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "174dfbf9-24a0-4f0e-9144-4477c485bc5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Root mean squared error: {root_mean_squared_error(testerYPredictions, testerY)}')\n",
    "print(f'Mean absolute error: {mean_absolute_error(testerYPredictions, testerY)}')\n",
    "print(f'R-Squared: {r2_score(testerYPredictions, testerY)}')\n",
    "print(f'Relative absolute error: {relative_absolute_error(testerYPredictions, testerY)}')\n",
    "print(f'Correlation Coefficients: {polyM.coef_}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22927b62-599a-42e5-9b90-80d9e31c6344",
   "metadata": {},
   "source": [
    "### All Inputs - Quadratic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8866e779-1a31-4baa-b7fc-1ec6f1d905c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The inputs to predict the price\n",
    "Inputs = newUsedCars[[\"year\", \"odometer\", \"conditionint\", \"title_statusint\", \"transmissionint\", \"manufacturerint\", \"cylindersint\", \"driveint\", \"typeint\"]]\n",
    "#Price, the output\n",
    "Price = newUsedCars[\"price\"]\n",
    "#Splitting the dataset into 80% training and 20% testing\n",
    "trainerX, testerX, trainerY, testerY = train_test_split(Inputs, Price, test_size=0.2, random_state=27)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb9d982e-5ed9-4d0a-8c75-84e8a74f025b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Quadratic Regression Model\n",
    "\n",
    "PolyRegress = PolynomialFeatures(2)\n",
    "polyFTrainer = PolyRegress.fit_transform(trainerX)\n",
    "polyFTester = PolyRegress.fit_transform(testerX)\n",
    "polyM = linear_model.LinearRegression()\n",
    "polyM.fit(polyFTrainer, trainerY)\n",
    "trainerYPredictions = polyM.predict(polyFTrainer)\n",
    "testerYPredictions = polyM.predict(polyFTester)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "926183ef-2180-45f6-8894-812d6d087456",
   "metadata": {},
   "source": [
    "#### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea78e62-f516-4baf-9cc4-62c3629f374d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Root mean squared error: {root_mean_squared_error(testerYPredictions, testerY)}')\n",
    "print(f'Mean absolute error: {mean_absolute_error(testerYPredictions, testerY)}')\n",
    "print(f'R-Squared: {r2_score(testerYPredictions, testerY)}')\n",
    "print(f'Relative absolute error: {relative_absolute_error(testerYPredictions, testerY)}')\n",
    "print(f'Correlation Coefficients: {polyM.coef_}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cdb87d8-0129-4ad3-9db8-b9f316842c5e",
   "metadata": {},
   "source": [
    "### Two Original Inputs - Cubic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef60716b-9cde-4e6b-8a1e-8f1eaea7582c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The inputs to predict the price\n",
    "Inputs = newUsedCars[[\"year\", \"odometer\"]]\n",
    "#Price, the output\n",
    "Price = newUsedCars[\"price\"]\n",
    "#Splitting the dataset into 80% training and 20% testing\n",
    "trainerX, testerX, trainerY, testerY = train_test_split(Inputs, Price, test_size=0.2, random_state=27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8f1b8ec-d72b-4a96-9c63-d19998f655b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Cubic Regression Model\n",
    "\n",
    "PolyRegress = PolynomialFeatures(3)\n",
    "polyFTrainer = PolyRegress.fit_transform(trainerX)\n",
    "polyFTester = PolyRegress.fit_transform(testerX)\n",
    "polyM = linear_model.LinearRegression()\n",
    "polyM.fit(polyFTrainer, trainerY)\n",
    "trainerYPredictions = polyM.predict(polyFTrainer)\n",
    "testerYPredictions = polyM.predict(polyFTester)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7410d9a8-3c7e-4cb7-95ce-5524d69becc5",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c11a240d-fa8c-4e9b-9d63-62cda4da718e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Root mean squared error: {root_mean_squared_error(testerYPredictions, testerY)}')\n",
    "print(f'Mean absolute error: {mean_absolute_error(testerYPredictions, testerY)}')\n",
    "print(f'R-Squared: {r2_score(testerYPredictions, testerY)}')\n",
    "print(f'Relative absolute error: {relative_absolute_error(testerYPredictions, testerY)}')\n",
    "print(f'Correlation Coefficients: {polyM.coef_}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42fc15d8-94b0-4127-9226-82973bea873c",
   "metadata": {},
   "source": [
    "### Four Best Inputs - Cubic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1c1d2c9-141f-4e57-9aae-75b28c5b9ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The inputs to predict the price\n",
    "Inputs = newUsedCars[[\"year\", \"odometer\", \"transmissionint\", \"cylindersint\"]]\n",
    "#Price, the output\n",
    "Price = newUsedCars[\"price\"]\n",
    "#Splitting the dataset into 80% training and 20% testing\n",
    "trainerX, testerX, trainerY, testerY = train_test_split(Inputs, Price, test_size=0.2, random_state=27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35390e30-8c07-4438-b78a-846fe8241a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Cubic Regression Model\n",
    "\n",
    "PolyRegress = PolynomialFeatures(3)\n",
    "polyFTrainer = PolyRegress.fit_transform(trainerX)\n",
    "polyFTester = PolyRegress.fit_transform(testerX)\n",
    "polyM = linear_model.LinearRegression()\n",
    "polyM.fit(polyFTrainer, trainerY)\n",
    "trainerYPredictions = polyM.predict(polyFTrainer)\n",
    "testerYPredictions = polyM.predict(polyFTester)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9e5010a-746f-4eed-be8d-9da0e37b140b",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89204a8a-ce2e-4371-85e8-8bb1b99af07a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Root mean squared error: {root_mean_squared_error(testerYPredictions, testerY)}')\n",
    "print(f'Mean absolute error: {mean_absolute_error(testerYPredictions, testerY)}')\n",
    "print(f'R-Squared: {r2_score(testerYPredictions, testerY)}')\n",
    "print(f'Relative absolute error: {relative_absolute_error(testerYPredictions, testerY)}')\n",
    "print(f'Correlation Coefficients: {polyM.coef_}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb1e6ee7-f2e3-40e9-a0fa-cbd2e909df9e",
   "metadata": {},
   "source": [
    "### All Inputs - Cubic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db61c827-4897-40f9-a981-fb20277f7da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The inputs to predict the price\n",
    "Inputs = newUsedCars[[\"year\", \"odometer\", \"conditionint\", \"title_statusint\", \"transmissionint\", \"manufacturerint\", \"cylindersint\", \"driveint\", \"typeint\"]]\n",
    "#Price, the output\n",
    "Price = newUsedCars[\"price\"]\n",
    "#Splitting the dataset into 80% training and 20% testing\n",
    "trainerX, testerX, trainerY, testerY = train_test_split(Inputs, Price, test_size=0.2, random_state=27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04bd0405-109e-4090-a0af-7d0419855fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Cubic Regression Model\n",
    "\n",
    "PolyRegress = PolynomialFeatures(3)\n",
    "polyFTrainer = PolyRegress.fit_transform(trainerX)\n",
    "polyFTester = PolyRegress.fit_transform(testerX)\n",
    "polyM = linear_model.LinearRegression()\n",
    "polyM.fit(polyFTrainer, trainerY)\n",
    "trainerYPredictions = polyM.predict(polyFTrainer)\n",
    "testerYPredictions = polyM.predict(polyFTester)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb0891d5-ceb6-40d1-8f72-9d74b01ff4a9",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d30cbb8-d4fb-4c41-b35d-df520945c170",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Root mean squared error: {root_mean_squared_error(testerYPredictions, testerY)}')\n",
    "print(f'Mean absolute error: {mean_absolute_error(testerYPredictions, testerY)}')\n",
    "print(f'R-Squared: {r2_score(testerYPredictions, testerY)}')\n",
    "print(f'Relative absolute error: {relative_absolute_error(testerYPredictions, testerY)}')\n",
    "print(f'Correlation Coefficients: {polyM.coef_}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d07582a5-b904-4dfd-a5f2-c951e3593535",
   "metadata": {},
   "source": [
    "## Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acc1f7fa-3b73-44b2-8e6a-d42a6debb2ce",
   "metadata": {},
   "source": [
    "* When both the Quadratic and Cubic models had very few inputs, originally only the age and mileage, they underfit tremendously, to the point of having a negative R-squared value\n",
    "* Even inputs with lower correlation values can still contribute to greater accuracy, both the Quadrtaic and Cubic models improved their accuracy tremendously when they had more inputs to work with regardless of the strength of correlation\n",
    "* Neither this model nor the quadratic model ran into overfitting the training dataset, meaning both the number of inputs and the degree of the model were low enough to keep the training set as a good indicator for testing.\n",
    "* Cubic regression seemed to be more extreme in its accuracy, where the more inputs that were added the more exponentially the accuracy of the model rose\n",
    "* This could indicate that Cubic regression is better for studying such a dataset than Quadratic regression, but only if the Cubic model has a large array of inputs to work with"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d247609-9fe5-4872-9ab3-c9aa707ae294",
   "metadata": {},
   "source": [
    "\n",
    "# -------------------------------Lasso Regression (Rachel)----------------------------------------\n",
    "\n",
    "For Lasso Regression I will create two models, one with all features and one with only the features with high correlations to price.\n",
    "\n",
    "The 3 features with the most correlation are:\n",
    "\n",
    "    Mileage\n",
    "    Transmission\n",
    "    Year\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70bc6810-237f-4e8e-af10-88cb0d04131a",
   "metadata": {},
   "outputs": [],
   "source": [
    "lass = Lasso()\n",
    "lass.fit(trainerX, trainerY)\n",
    "print(lass.intercept_)\n",
    "print(lass.coef_)\n",
    "lassPredict = lass.predict(testerX)\n",
    "print(\"Score \", root_mean_squared_error(testerY, lassPredict))\n",
    "print(f'R-Squared: {r2_score(testerY, lassPredict)}')\n",
    "\n",
    "\n",
    "print()\n",
    "print()\n",
    "refinedInput = newUsedCars[[\"year\", \"odometer\",\"transmissionint\"]]\n",
    "rtrainerX, rtesterX, rtrainerY, rtesterY = train_test_split(refinedInput, Price, test_size=0.2, random_state=27)\n",
    "\n",
    "rlass = Lasso()\n",
    "rlass.fit(rtrainerX, rtrainerY)\n",
    "print(rlass.intercept_)\n",
    "print(rlass.coef_)\n",
    "rlassPredict = rlass.predict(rtesterX)\n",
    "print(\"Score \", root_mean_squared_error(rtesterY, rlassPredict))\n",
    "print(f'R-Squared: {r2_score(rtesterY, rlassPredict)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "556f7826-7259-47c4-b6a9-002116a5c07f",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "**My theory that less criterias would lead to a higher R-Squared value was wrong.**\n",
    "\n",
    "My finding with Lasso Regression is that there is a 55% accuracy with this models output. Because Lasso experiences hardly any changes when tuning is done though the changing of hyperparameters, I will not be changing the alpha in attempts to make the model more accurate.\n",
    "\n",
    "**However, improvements can be made with data scaling**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "616f95bf-e89d-4212-89ec-a85de4fbc2a0",
   "metadata": {},
   "source": [
    "# ------------Decision tree Regression (Bilal)------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b27477-fd69-419e-ab48-e7b5c3a73bf9",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "x = newUsedCars[['odometer']]\n",
    "y = newUsedCars['price']\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=27)\n",
    "RTModel = DecisionTreeRegressor(random_state=27)\n",
    "RTModel.fit(X_train, y_train)\n",
    "y_pred = RTModel.predict(X_test)\n",
    "\n",
    "print(f'Root mean squared error: {root_mean_squared_error(y_test, y_pred)}')\n",
    "print(f'Mean absolute error: {mean_absolute_error(y_test, y_pred)}')\n",
    "print(f'R-Squared: {r2_score(y_test, y_pred)}')\n",
    "print(f'Relative absolute error: {relative_absolute_error(y_test, y_pred)}')\n",
    "print(f'Correlation Coefficients: {RTModel.feature_importances_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13648107-0226-44bd-914d-46c48741d642",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "x = newUsedCars[['odometer', 'year', 'modelint']]\n",
    "y = newUsedCars['price']\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=27)\n",
    "RTModel = DecisionTreeRegressor(random_state=27)\n",
    "RTModel.fit(X_train, y_train)\n",
    "y_pred = RTModel.predict(X_test)\n",
    "\n",
    "print(f'Root mean squared error: {root_mean_squared_error(y_test, y_pred)}')\n",
    "print(f'Mean absolute error: {mean_absolute_error(y_test, y_pred)}')\n",
    "print(f'R-Squared: {r2_score(y_test, y_pred)}')\n",
    "print(f'Relative absolute error: {relative_absolute_error(y_test, y_pred)}')\n",
    "print(f'Correlation Coefficients: {RTModel.feature_importances_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b972b44-fdb6-42d5-be29-012abdddc927",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "x = newUsedCars[['odometer', 'year', 'modelint', 'transmissionint', 'manufacturerint']]\n",
    "y = newUsedCars['price']\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=27)\n",
    "RTModel = DecisionTreeRegressor(random_state=27)\n",
    "RTModel.fit(X_train, y_train)\n",
    "y_pred = RTModel.predict(X_test)\n",
    "\n",
    "print(f'Root mean squared error: {root_mean_squared_error(y_test, y_pred)}')\n",
    "print(f'Mean absolute error: {mean_absolute_error(y_test, y_pred)}')\n",
    "print(f'R-Squared: {r2_score(y_test, y_pred)}')\n",
    "print(f'Relative absolute error: {relative_absolute_error(y_test, y_pred)}')\n",
    "print(f'Correlation Coefficients: {RTModel.feature_importances_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31f651db-7601-4b63-95f5-0a81382b52f8",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "x = newUsedCars[['odometer', 'year', 'modelint', 'transmissionint', 'manufacturerint', 'cylindersint']]\n",
    "y = newUsedCars['price']\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=27)\n",
    "RTModel = DecisionTreeRegressor( random_state=27)\n",
    "RTModel.fit(X_train, y_train)\n",
    "y_pred = RTModel.predict(X_test)\n",
    "\n",
    "print(f'Root mean squared error: {root_mean_squared_error(y_test, y_pred)}')\n",
    "print(f'Mean absolute error: {mean_absolute_error(y_test, y_pred)}')\n",
    "print(f'R-Squared: {r2_score(y_test, y_pred)}')\n",
    "print(f'Relative absolute error: {relative_absolute_error(y_test, y_pred)}')\n",
    "print(f'Correlation Coefficients: {RTModel.feature_importances_}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63f769cd-4d1f-4c9f-9548-db97223ea4e3",
   "metadata": {},
   "source": [
    "#### The decision tree regression model performed quite well on the data set. As more input features were added the performance increased quite a lot. The decision tree regression model is quite suitable for this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ca0b11e-3461-411b-b794-a74385792b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = newUsedCars[['odometer', 'year', 'modelint', 'transmissionint', 'manufacturerint', 'cylindersint', 'driveint']]\n",
    "y = newUsedCars['price']\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=27)\n",
    "RTModel = DecisionTreeRegressor(random_state=27)\n",
    "RTModel.fit(X_train, y_train)\n",
    "y_pred = RTModel.predict(X_test)\n",
    "\n",
    "print(f'Root mean squared error: {root_mean_squared_error(y_test, y_pred)}')\n",
    "print(f'Mean absolute error: {mean_absolute_error(y_test, y_pred)}')\n",
    "print(f'R-Squared: {r2_score(y_test, y_pred)}')\n",
    "print(f'Relative absolute error: {relative_absolute_error(y_test, y_pred)}')\n",
    "print(f'Correlation Coefficients: {RTModel.feature_importances_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75a81fd2-2a6e-41b5-9668-d2ac8bd500c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = newUsedCars[['odometer', 'year', 'modelint', 'transmissionint', 'manufacturerint', 'cylindersint', 'driveint']]\n",
    "y = newUsedCars['price']\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=27)\n",
    "RTModel = DecisionTreeRegressor(max_depth=26, min_samples_split=18, min_samples_leaf=9,random_state=27)\n",
    "RTModel.fit(X_train, y_train)\n",
    "y_pred = RTModel.predict(X_test)\n",
    "            \n",
    "print(f'Root mean squared error: {root_mean_squared_error(y_test, y_pred)}')\n",
    "print(f'Mean absolute error: {mean_absolute_error(y_test, y_pred)}')\n",
    "print(f'R-Squared: {r2_score(y_test, y_pred)}')\n",
    "print(f'Relative absolute error: {relative_absolute_error(y_test, y_pred)}')\n",
    "print(f'Correlation Coefficients: {RTModel.feature_importances_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5adb6a1-c7c3-4c01-8cec-21a91254e459",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = usedDealerShips[['odometer', 'year','modelint', 'transmissionint', 'manufacturerint',  \"cylindersint\"]]\n",
    "y = usedDealerShips['price']\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=27)\n",
    "RTModel = DecisionTreeRegressor(max_depth=23, min_samples_split=27, min_samples_leaf=5, random_state=27)\n",
    "RTModel.fit(X_train, y_train)\n",
    "y_pred = RTModel.predict(X_test)\n",
    "\n",
    "print(f'Root mean squared error: {root_mean_squared_error( y_test, y_pred)}')\n",
    "print(f'Mean absolute error: {mean_absolute_error(y_test, y_pred)}')\n",
    "print(f'R-Squared: {r2_score(y_test, y_pred)}')\n",
    "print(f'Relative absolute error: {relative_absolute_error(y_test, y_pred)}')\n",
    "print(f'Correlation Coefficients: {RTModel.feature_importances_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42c02f67-fe2f-4f9a-a9d8-f223bc712913",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = vehicles[['odometer', 'year','modelint', 'transmissionint', 'manufacturerint']]\n",
    "y = vehicles['price']\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=27)\n",
    "RTModel = DecisionTreeRegressor(max_depth=23, min_samples_split=23, min_samples_leaf=7,random_state=27)\n",
    "RTModel.fit(X_train, y_train)\n",
    "y_pred = RTModel.predict(X_test)\n",
    "print(f'Root mean squared error: {root_mean_squared_error( y_test, y_pred)}')\n",
    "print(f'Mean absolute error: {mean_absolute_error(y_test, y_pred)}')\n",
    "print(f'R-Squared: {r2_score(y_test, y_pred)}')\n",
    "print(f'Relative absolute error: {relative_absolute_error(y_test, y_pred)}')\n",
    "print(f'Correlation Coefficients: {RTModel.feature_importances_}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "357e33c8-20c9-4f65-8596-cb647b1424ee",
   "metadata": {},
   "source": [
    "#### When compared between the 3 datasets with different preprocessing, it performed the best on the data set where no distinction was made between independent sellers and dealerships. The data set where it performed the best was also the dataset where duplicate descriptions were not removed which could be a factor on why predictive modeling is better on the dataset. The dataset with entries that are likely from dealerships performed better than the dataset with independent sellers. This can indicate that the dealerships use the input features in their pricing decisions to a larger extent."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
